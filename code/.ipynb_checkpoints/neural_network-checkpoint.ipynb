{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 1, 0],\n",
      "        [1, 0, 1, 1],\n",
      "        [0, 1, 0, 1]]) \n",
      "Shape:  torch.Size([3, 4])\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [0]]) \n",
      "Shape:  torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "# INPUT TENSOR\n",
    "# No of features i.e dimension of matrix \n",
    "# NO OF FEATURES REPRESENTS DIMENSION OF A MATRIX\n",
    "\n",
    "X = torch.tensor([[1, 0, 1, 0], [1, 0, 1, 1], [0, 1, 0, 1]]) # Indexes i.e row samples = 3, Columns i.e Features =4\n",
    "\n",
    "\n",
    "y = torch.tensor([[1], [1], [0]])\n",
    "print(X, \"\\nShape: \", X.shape)\n",
    "print(y, \"\\nShape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return (1/ 1 + torch.exp(-x))\n",
    "\n",
    "def derivative_sigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLE INITIALIZATION\n",
    "\n",
    "epoch = 7000 # Setting training iterations\n",
    "\n",
    "# IMPORTANCE OF LEARNING RATE - \n",
    "lr = 0.1\n",
    "\n",
    "# NO OF FEATURES i.e COLUMNS INDICATES NO OF NEURONS IN INPUT LAYER\n",
    "input_neurons = X.shape[1] # This is no of features of matrix\n",
    "\n",
    "# HIDDEN LAYER\n",
    "hidden_neurons = 3\n",
    "# NO OF OUTPUT DEPENDS ON PROBLEM i.e NO OF CLASSES TO PREDICT\n",
    "output_neurons = 1\n",
    "\n",
    "# WEIGHT AND BIAS INITIALIZATION, NEEDS SOME CLARIFICATION\n",
    "wh = torch.randn(input_neurons, hidden_neurons)\n",
    "bh = torch.randn(1, hidden_neurons)\n",
    "\n",
    "wout = torch.randn(hidden_neurons, output_neurons)\n",
    "bout = torch.randn(1, output_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #2 'mat2' in call to _th_mm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c01904d6cc83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Forward Propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mhidden_layer_input1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mhidden_layer_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_layer_input1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhidden_layer_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'mat2' in call to _th_mm"
     ]
    }
   ],
   "source": [
    "# CODE FOR NETWORK, WHICH CONTAINS ONE HIDDEN LAYER \n",
    "\n",
    "for i in range(epoch):\n",
    "    # Forward Propagation\n",
    "    hidden_layer_input1 = torch.mm(X, wh)\n",
    "    hidden_layer_input = hidden_layer_input1 + bh\n",
    "    hidden_layer_activations = sigmoid(hidden_layer_input)\n",
    "    \n",
    "    output_layer_input1 = torch.mm(hidden_layer_activations, wout)\n",
    "    output_layer_input = output_layer_input1 + bout\n",
    "    output = sigmoid(output_layer_input)\n",
    "    \n",
    "    \n",
    "    # BACKPROPAGATION\n",
    "    error = y - output\n",
    "    slope_output_layer = derivative_sigmoid(output)\n",
    "    slope_hidden_layer = derivative_sigmoid(hidden_layer_activations)\n",
    "    \n",
    "    d_output = error * slope_output_layer\n",
    "    error_hidden_layer = torch.mm(d_output, wout.t())\n",
    "    d_hiddenlayer = error_hidden_layer * slope_hidden_layer\n",
    "    \n",
    "    # UPDATES OF WEIGHTS AND BIASES\n",
    "    \n",
    "    wout += torch.mm(hidden_layer_activations.t(), d_output) * lr\n",
    "    bout += d_output.sum() * lr\n",
    "    wh += torch.mm(X.t(), d_hiddenlayer) * lr\n",
    "    bh += d_output.sum() * lr\n",
    "    \n",
    "    \n",
    "print(\"Actual, \\n\", y, \"\\n\")\n",
    "print(\"Predicted \\n\", output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
